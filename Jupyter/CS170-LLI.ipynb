{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Erin Beatrice Micaela G. Reyes\n",
        "\n",
        "Von Derwin Caibigan\n",
        "\n",
        "\n",
        "\n",
        "BM1"
      ],
      "metadata": {
        "id": "C97xHAa50MiB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction"
      ],
      "metadata": {
        "id": "GF8J6WkEdlvJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Low-light image processing is a crucial step in ensuring the quality and integrity of data. Due to the challenges posed by insufficient illumination, images may have low visibility and one may lose out on important details.\n",
        "\n",
        "This project will compare and contrast two low-light image processing algorithms, one traditional and one deep-learning. These algorithms will be [blank] for traditional and Retinex for deep-learning. After using these algorithms, a YOLOv5 model will be used to compare the effects of both algorithms on object identification."
      ],
      "metadata": {
        "id": "gYt2LwT1douA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep-Learning (Retinex)\n"
      ],
      "metadata": {
        "id": "21YtQ2-eY55U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# List of file paths.\n",
        "file_path = '/content/drive/MyDrive/'\n",
        "\n",
        "src = 'datasets/ds_nonaugmented/'\n",
        "\n",
        "part1_label = 'labels/part1/'\n",
        "part2_label = 'labels/part2/'\n",
        "part3_label = 'labels/part3/'\n",
        "\n",
        "part1_images = 'images/part1/'\n",
        "part2_images = 'images/part2/'\n",
        "part3_images = 'images/part3/'\n",
        "\n",
        "_valid = 'valid/'\n",
        "_train = 'train/'\n",
        "_test = 'test/'\n",
        "\n",
        "part1_yaml = 'data1.yaml'\n",
        "part2_yaml = 'data2.yaml'\n",
        "part3_yaml = 'data3.yaml'\n",
        "\n",
        "subfolder_split = [_train, _test, _valid]\n",
        "subfolder_images = [part1_images, part2_images, part3_images]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSzLrosE_0dA",
        "outputId": "53a2abe4-d833-4df3-e667-3467c35fc7f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHOZCKwsZJOE",
        "outputId": "912d5fe1-2d9b-4ffe-fa7f-ddd4da953d28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.23.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To start, we must first install opencv-python. Opencv-python"
      ],
      "metadata": {
        "id": "-5aDlBxOe-MX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "gtAk1Mz2ZJFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def single_scale_retinex(image, sigma, gamma):\n",
        "    image_float = np.float32(image) / 255.0\n",
        "    log_image = np.log10(image_float + 1e-10)\n",
        "    blurred_image = cv2.GaussianBlur(log_image, (0, 0), sigma)\n",
        "    retinex_image = log_image - blurred_image\n",
        "    retinex_image = np.clip((retinex_image + 1) * 64, 0, 255).astype(np.uint8)\n",
        "    retinex_image = np.clip(retinex_image ** gamma, 0, 255).astype(np.uint8)\n",
        "\n",
        "    return retinex_image"
      ],
      "metadata": {
        "id": "7xlB3__pyfvQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def enhance_images_in_directory(input_directory, sigma=15, gamma=1.1):\n",
        "    if not os.path.exists(output_directory):\n",
        "        os.makedirs(output_directory)\n",
        "\n",
        "    for filename in os.listdir(input_directory):\n",
        "        if filename.endswith(('.jpg', '.png', '.jpeg')):\n",
        "            input_path = os.path.join(input_directory, filename)\n",
        "\n",
        "            input_image = cv2.imread(input_path)\n",
        "            enhanced_image = single_scale_retinex(input_image, sigma, gamma)\n",
        "            cv2.imwrite(input_path, enhanced_image)"
      ],
      "metadata": {
        "id": "c30Q2l1faj37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_directory = \"/content/drive/MyDrive/dest/valid/images/part1\"\n",
        "\n",
        "# Call the function to enhance and replace the original images\n",
        "enhance_images_in_directory(input_directory)"
      ],
      "metadata": {
        "id": "BWy1eMvCal51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_directory = \"/content/drive/MyDrive/dest/valid/images/part2\"\n",
        "\n",
        "# Call the function to enhance and replace the original images\n",
        "enhance_images_in_directory(input_directory)"
      ],
      "metadata": {
        "id": "9OIr9CmIwjPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_directory = \"/content/drive/MyDrive/dest/valid/images/part3\"\n",
        "\n",
        "# Call the function to enhance and replace the original images\n",
        "enhance_images_in_directory(input_directory)"
      ],
      "metadata": {
        "id": "Dyrh3P8XwjZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "azmWtlWFe3n5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Traditional ()"
      ],
      "metadata": {
        "id": "HOOCiVK1f2zK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# YOLOv5 (Model)\n",
        "\n"
      ],
      "metadata": {
        "id": "3h71_EiEOc2r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1iChNq59dlwp",
        "outputId": "1aedb86a-8d84-4ee0-b3e4-785067e10f6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.0.227-py3-none-any.whl (660 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/660.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/660.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m378.9/660.5 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m655.4/660.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m660.5/660.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.22.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.23.5)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.16.0+cu118)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.1)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.5.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.12.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Collecting thop>=0.1.1 (from ultralytics)\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2023.11.17)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Installing collected packages: thop, ultralytics\n",
            "Successfully installed thop-0.1.1.post2209072238 ultralytics-8.0.227\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import ultralytics\n",
        "\n",
        "ultralytics.checks()\n",
        "\n",
        "yolov5 = YOLO('yolov5s.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFEQP9b8Zf0M",
        "outputId": "a6018e09-fa18-4c58-a261-3a5147b72b6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.0.227 🚀 Python-3.10.12 torch-2.1.0+cu118 CPU (Intel Xeon 2.20GHz)\n",
            "Setup complete ✅ (2 CPUs, 12.7 GB RAM, 27.0/107.7 GB disk)\n",
            "PRO TIP 💡 Replace 'model=yolov5s.pt' with new 'model=yolov5su.pt'.\n",
            "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
            "\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov5su.pt to 'yolov5su.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 17.7M/17.7M [00:00<00:00, 76.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "file_path ='/content/drive/MyDrive/datasets (1)/dest'\n",
        "print(os.path.exists(file_path))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nC4RaI-Rene0",
        "outputId": "756b5393-7ee9-4bd2-e131-4699e07629e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "part1_results = yolov5.train(\n",
        "    data = '/content/drive/MyDrive/datasets/dest/data1.yaml',\n",
        "    epochs=3, # Preferred epochs are in the range of 1-10, so we chose 10 since more epochs can lead to better performance, up to a certain extent.\n",
        "    batch=16, # A good starting point, since smaller batch sizes train slower but for the tradeoff of faster convergence.\n",
        "    name='motorcycle_rider_helmet_p1_model'\n",
        ")"
      ],
      "metadata": {
        "id": "-B5lyzLaAGrJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39083371-607e-49ba-fbb5-08082191b592"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.0.226 🚀 Python-3.10.12 torch-2.1.0+cu118 CPU (Intel Xeon 2.20GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov5s.pt, data=/content/drive/MyDrive/datasets/dest/data1.yaml, epochs=3, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=0, project=None, name=motorcycle_rider_helmet_p1_model2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.0, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/motorcycle_rider_helmet_p1_model2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      3520  ultralytics.nn.modules.conv.Conv             [3, 32, 6, 2, 2]              \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     18816  ultralytics.nn.modules.block.C3              [64, 64, 1]                   \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    115712  ultralytics.nn.modules.block.C3              [128, 128, 2]                 \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  3    625152  ultralytics.nn.modules.block.C3              [256, 256, 3]                 \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1]                 \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1]              \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    361984  ultralytics.nn.modules.block.C3              [512, 256, 1, False]          \n",
            " 14                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n",
            " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 17                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \n",
            " 18                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 20                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \n",
            " 21                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 23                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1, False]          \n",
            " 24        [17, 20, 23]  1   2119144  ultralytics.nn.modules.head.Detect           [8, [128, 256, 512]]          \n",
            "YOLOv5s summary: 262 layers, 9125288 parameters, 9125272 gradients, 24.1 GFLOPs\n",
            "\n",
            "Transferred 427/427 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/motorcycle_rider_helmet_p1_model2', view at http://localhost:6006/\n",
            "Freezing layer 'model.24.dfl.conv.weight'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/datasets/dest/train/labels/part1... 505 images, 514 backgrounds, 0 corrupt: 100%|██████████| 1010/1010 [04:58<00:00,  3.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/MyDrive/datasets/dest/train/labels/part1.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/datasets/dest/valid/labels/part1... 144 images, 145 backgrounds, 0 corrupt: 100%|██████████| 288/288 [01:20<00:00,  3.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/MyDrive/datasets/dest/valid/labels/part1.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/motorcycle_rider_helmet_p1_model2/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000833, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.0005), 75 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/motorcycle_rider_helmet_p1_model2\u001b[0m\n",
            "Starting training for 3 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        1/3         0G       1.71      2.671      1.398          2        640: 100%|██████████| 64/64 [36:40<00:00, 34.39s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [03:34<00:00, 23.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        288        814      0.618       0.19     0.0959     0.0518\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        2/3         0G      1.455       2.27      1.252         16        640: 100%|██████████| 64/64 [36:54<00:00, 34.60s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [03:37<00:00, 24.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        288        814      0.633      0.205      0.123     0.0721\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        3/3         0G      1.368      2.071      1.204         36        640: 100%|██████████| 64/64 [36:55<00:00, 34.62s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [03:38<00:00, 24.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        288        814      0.618      0.232       0.11     0.0657\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "3 epochs completed in 2.027 hours.\n",
            "Optimizer stripped from runs/detect/motorcycle_rider_helmet_p1_model2/weights/last.pt, 18.5MB\n",
            "Optimizer stripped from runs/detect/motorcycle_rider_helmet_p1_model2/weights/best.pt, 18.5MB\n",
            "\n",
            "Validating runs/detect/motorcycle_rider_helmet_p1_model2/weights/best.pt...\n",
            "Ultralytics YOLOv8.0.226 🚀 Python-3.10.12 torch-2.1.0+cu118 CPU (Intel Xeon 2.20GHz)\n",
            "YOLOv5s summary (fused): 193 layers, 9114632 parameters, 0 gradients, 23.8 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [03:27<00:00, 23.03s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        288        814      0.633      0.205      0.123     0.0721\n",
            "        Passenger-Full        288         34          1          0      0.043     0.0234\n",
            "        Passenger-Half        288        113      0.313      0.266      0.201     0.0936\n",
            "            Rider-Full        288        410      0.303      0.529      0.294      0.185\n",
            "            Rider-Half        288        244      0.182      0.434      0.184      0.119\n",
            "         Rider-Invalid        288          7          1          0    0.00822    0.00772\n",
            "       Rider-No-Helmet        288          6          1          0    0.00797    0.00454\n",
            "Speed: 3.7ms preprocess, 686.9ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/motorcycle_rider_helmet_p1_model2\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the results\n",
        "!zip -r /content/runs.zip /content/runs\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "files.download('/content/runs.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "id": "_oAy6k_YWFf4",
        "outputId": "c8375e0e-a22a-4467-88b0-cf33d5a52f4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/runs/ (stored 0%)\n",
            "  adding: content/runs/detect/ (stored 0%)\n",
            "  adding: content/runs/detect/motorcycle_rider_helmet_p2_model/ (stored 0%)\n",
            "  adding: content/runs/detect/motorcycle_rider_helmet_p2_model/val_batch1_labels.jpg (deflated 7%)\n",
            "  adding: content/runs/detect/motorcycle_rider_helmet_p2_model/val_batch0_labels.jpg (deflated 7%)\n",
            "  adding: content/runs/detect/motorcycle_rider_helmet_p2_model/results.csv (deflated 77%)\n",
            "  adding: content/runs/detect/motorcycle_rider_helmet_p2_model/train_batch0.jpg (deflated 2%)\n",
            "  adding: content/runs/detect/motorcycle_rider_helmet_p2_model/args.yaml (deflated 52%)\n",
            "  adding: content/runs/detect/motorcycle_rider_helmet_p2_model/weights/ (stored 0%)\n",
            "  adding: content/runs/detect/motorcycle_rider_helmet_p2_model/weights/last.pt (deflated 8%)\n",
            "  adding: content/runs/detect/motorcycle_rider_helmet_p2_model/weights/best.pt (deflated 8%)\n",
            "  adding: content/runs/detect/motorcycle_rider_helmet_p2_model/val_batch1_pred.jpg (deflated 8%)\n",
            "  adding: content/runs/detect/motorcycle_rider_helmet_p2_model/val_batch2_pred.jpg (deflated 8%)\n",
            "  adding: content/runs/detect/motorcycle_rider_helmet_p2_model/val_batch0_pred.jpg (deflated 8%)\n",
            "  adding: content/runs/detect/motorcycle_rider_helmet_p2_model/confusion_matrix_normalized.png (deflated 22%)\n",
            "  adding: content/runs/detect/motorcycle_rider_helmet_p2_model/val_batch2_labels.jpg (deflated 7%)\n",
            "  adding: content/runs/detect/motorcycle_rider_helmet_p2_model/R_curve.png (deflated 13%)\n",
            "  adding: content/runs/detect/motorcycle_rider_helmet_p2_model/F1_curve.png (deflated 15%)\n",
            "  adding: content/runs/detect/motorcycle_rider_helmet_p2_model/PR_curve.png (deflated 15%)\n",
            "  adding: content/runs/detect/motorcycle_rider_helmet_p2_model/P_curve.png (deflated 11%)\n",
            "  adding: content/runs/detect/motorcycle_rider_helmet_p2_model/train_batch1.jpg (deflated 2%)\n",
            "  adding: content/runs/detect/motorcycle_rider_helmet_p2_model/labels_correlogram.jpg (deflated 42%)\n",
            "  adding: content/runs/detect/motorcycle_rider_helmet_p2_model/events.out.tfevents.1702356826.fe8c2745d2aa.257.0 (deflated 94%)\n",
            "  adding: content/runs/detect/motorcycle_rider_helmet_p2_model/labels.jpg (deflated 27%)\n",
            "  adding: content/runs/detect/motorcycle_rider_helmet_p2_model/results.png (deflated 8%)\n",
            "  adding: content/runs/detect/motorcycle_rider_helmet_p2_model/train_batch2.jpg (deflated 2%)\n",
            "  adding: content/runs/detect/motorcycle_rider_helmet_p2_model/confusion_matrix.png (deflated 25%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9b6fd50f-6501-4343-9d15-3c837878da7c\", \"runs.zip\", 40413480)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "part2_results = yolov5.train(\n",
        "    data = '/content/drive/MyDrive/datasets/dest/data2.yaml',\n",
        "    epochs=3, # Preferred epochs are in the range of 1-10, so we chose 10 since more epochs can lead to better performance, up to a certain extent.\n",
        "    batch=16, # A good starting point, since smaller batch sizes train slower but for the tradeoff of faster convergence.\n",
        "    name='motorcycle_rider_helmet_p2_model'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4E6a_jTIiHvO",
        "outputId": "ab71525c-4162-40f3-dcf7-86a8f7265715"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.0.227 🚀 Python-3.10.12 torch-2.1.0+cu118 CPU (Intel Xeon 2.20GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov5s.pt, data=/content/drive/MyDrive/datasets/dest/data2.yaml, epochs=3, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=motorcycle_rider_helmet_p2_model, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/motorcycle_rider_helmet_p2_model\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 755k/755k [00:00<00:00, 22.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding model.yaml nc=80 with nc=8\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      3520  ultralytics.nn.modules.conv.Conv             [3, 32, 6, 2, 2]              \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     18816  ultralytics.nn.modules.block.C3              [64, 64, 1]                   \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    115712  ultralytics.nn.modules.block.C3              [128, 128, 2]                 \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  3    625152  ultralytics.nn.modules.block.C3              [256, 256, 3]                 \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1]                 \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1]              \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    361984  ultralytics.nn.modules.block.C3              [512, 256, 1, False]          \n",
            " 14                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n",
            " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 17                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \n",
            " 18                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 20                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \n",
            " 21                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 23                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1, False]          \n",
            " 24        [17, 20, 23]  1   2119144  ultralytics.nn.modules.head.Detect           [8, [128, 256, 512]]          \n",
            "YOLOv5s summary: 262 layers, 9125288 parameters, 9125272 gradients, 24.1 GFLOPs\n",
            "\n",
            "Transferred 421/427 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/motorcycle_rider_helmet_p2_model', view at http://localhost:6006/\n",
            "Freezing layer 'model.24.dfl.conv.weight'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/datasets/dest/train/labels/part2.cache... 505 images, 557 backgrounds, 0 corrupt: 100%|██████████| 1010/1010 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/datasets/dest/valid/labels/part2.cache... 144 images, 153 backgrounds, 0 corrupt: 100%|██████████| 288/288 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/motorcycle_rider_helmet_p2_model/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000833, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.0005), 75 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/motorcycle_rider_helmet_p2_model\u001b[0m\n",
            "Starting training for 3 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        1/3         0G       2.63      7.228      1.859          0        640: 100%|██████████| 64/64 [31:49<00:00, 29.83s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [05:47<00:00, 38.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        288        506      0.491      0.189     0.0671     0.0247\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        2/3         0G      2.098      3.598      1.461          7        640: 100%|██████████| 64/64 [31:08<00:00, 29.20s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [03:11<00:00, 21.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        288        506      0.534     0.0891     0.0533     0.0209\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        3/3         0G      1.988      3.163      1.458          2        640: 100%|██████████| 64/64 [31:09<00:00, 29.21s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [02:57<00:00, 19.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        288        506      0.421      0.237      0.123     0.0486\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "3 epochs completed in 1.771 hours.\n",
            "Optimizer stripped from runs/detect/motorcycle_rider_helmet_p2_model/weights/last.pt, 18.5MB\n",
            "Optimizer stripped from runs/detect/motorcycle_rider_helmet_p2_model/weights/best.pt, 18.5MB\n",
            "\n",
            "Validating runs/detect/motorcycle_rider_helmet_p2_model/weights/best.pt...\n",
            "Ultralytics YOLOv8.0.227 🚀 Python-3.10.12 torch-2.1.0+cu118 CPU (Intel Xeon 2.20GHz)\n",
            "YOLOv5s summary (fused): 193 layers, 9114632 parameters, 0 gradients, 23.8 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [02:52<00:00, 19.17s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        288        506      0.422      0.235      0.124     0.0487\n",
            "        Passenger-Full        288         63      0.162      0.571      0.176     0.0631\n",
            "        Passenger-Half        288         78      0.339      0.167      0.202     0.0807\n",
            "     Passenger-Invalid        288          3          1          0     0.0726     0.0283\n",
            "            Rider-Full        288        209      0.255      0.459      0.255      0.106\n",
            "            Rider-Half        288        147      0.199      0.449      0.161     0.0629\n",
            "         Rider-Invalid        288          5          0          0          0          0\n",
            "       Rider-No-Helmet        288          1          1          0          0          0\n",
            "Speed: 2.2ms preprocess, 573.4ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/motorcycle_rider_helmet_p2_model\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "part3_results = yolov5.train(\n",
        "    data = '/content/drive/MyDrive/datasets/dest/data3.yaml',\n",
        "    epochs=3, # Preferred epochs are in the range of 1-10, so we chose 10 since more epochs can lead to better performance, up to a certain extent.\n",
        "    batch=16, # A good starting point, since smaller batch sizes train slower but for the tradeoff of faster convergence.\n",
        "    name='motorcycle_rider_helmet_p3_model'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aDX9ogfiH8V",
        "outputId": "ccebf518-fdcd-4ed7-db76-f2106c46e217"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.0.226 🚀 Python-3.10.12 torch-2.1.0+cu118 CPU (Intel Xeon 2.20GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov5s.pt, data=/content/drive/MyDrive/datasets/dest/data3.yaml, epochs=3, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=motorcycle_rider_helmet_p3_model4, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/motorcycle_rider_helmet_p3_model4\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 755k/755k [00:00<00:00, 4.05MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding model.yaml nc=80 with nc=8\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      3520  ultralytics.nn.modules.conv.Conv             [3, 32, 6, 2, 2]              \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     18816  ultralytics.nn.modules.block.C3              [64, 64, 1]                   \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    115712  ultralytics.nn.modules.block.C3              [128, 128, 2]                 \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  3    625152  ultralytics.nn.modules.block.C3              [256, 256, 3]                 \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1]                 \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1]              \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    361984  ultralytics.nn.modules.block.C3              [512, 256, 1, False]          \n",
            " 14                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n",
            " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 17                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \n",
            " 18                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 20                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \n",
            " 21                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 23                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1, False]          \n",
            " 24        [17, 20, 23]  1   2119144  ultralytics.nn.modules.head.Detect           [8, [128, 256, 512]]          \n",
            "YOLOv5s summary: 262 layers, 9125288 parameters, 9125272 gradients, 24.1 GFLOPs\n",
            "\n",
            "Transferred 421/427 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/motorcycle_rider_helmet_p3_model4', view at http://localhost:6006/\n",
            "Freezing layer 'model.24.dfl.conv.weight'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/datasets/dest/train/labels/part3... 505 images, 610 backgrounds, 0 corrupt: 100%|██████████| 1010/1010 [04:19<00:00,  3.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/MyDrive/datasets/dest/train/labels/part3.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/datasets/dest/valid/labels/part3... 144 images, 186 backgrounds, 0 corrupt: 100%|██████████| 288/288 [01:00<00:00,  4.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/MyDrive/datasets/dest/valid/labels/part3.cache\n",
            "Plotting labels to runs/detect/motorcycle_rider_helmet_p3_model4/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000833, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.0005), 75 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/motorcycle_rider_helmet_p3_model4\u001b[0m\n",
            "Starting training for 3 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        1/3         0G       2.09        7.9      1.647          0        640: 100%|██████████| 64/64 [36:40<00:00, 34.39s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [03:30<00:00, 23.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        288        244      0.792     0.0541     0.0309     0.0153\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        2/3         0G      1.811      3.771      1.436          3        640: 100%|██████████| 64/64 [36:13<00:00, 33.96s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [03:42<00:00, 24.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        288        244      0.655     0.0694     0.0508     0.0261\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        3/3         0G      1.734      3.422      1.422          4        640: 100%|██████████| 64/64 [36:31<00:00, 34.24s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [03:27<00:00, 23.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        288        244      0.657      0.109     0.0519     0.0249\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "3 epochs completed in 2.005 hours.\n",
            "Optimizer stripped from runs/detect/motorcycle_rider_helmet_p3_model4/weights/last.pt, 18.5MB\n",
            "Optimizer stripped from runs/detect/motorcycle_rider_helmet_p3_model4/weights/best.pt, 18.5MB\n",
            "\n",
            "Validating runs/detect/motorcycle_rider_helmet_p3_model4/weights/best.pt...\n",
            "Ultralytics YOLOv8.0.226 🚀 Python-3.10.12 torch-2.1.0+cu118 CPU (Intel Xeon 2.20GHz)\n",
            "YOLOv5s summary (fused): 193 layers, 9114632 parameters, 0 gradients, 23.8 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [03:14<00:00, 21.60s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        288        244      0.655     0.0694       0.05     0.0258\n",
            "        Passenger-Full        288          9          1          0      0.131     0.0799\n",
            "        Passenger-Half        288         37          0          0     0.0517     0.0213\n",
            "     Passenger-Invalid        288          5          1          0    0.00702    0.00258\n",
            "   Passenger-No-Helmet        288          6          1          0          0          0\n",
            "            Rider-Full        288         87      0.154      0.115     0.0783     0.0401\n",
            "            Rider-Half        288         75      0.085       0.44     0.0805     0.0356\n",
            "         Rider-Invalid        288         16          1          0     0.0155    0.00476\n",
            "       Rider-No-Helmet        288          9          1          0     0.0363      0.022\n",
            "Speed: 2.9ms preprocess, 649.8ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/motorcycle_rider_helmet_p3_model4\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "\n",
        "https://santhalakshminarayana.github.io/blog/retinex-image-enhancement\n",
        "\n",
        "https://github.com/pvnieo/Low-light-Image-Enhancement\n"
      ],
      "metadata": {
        "id": "fwj5e5K5fKtk"
      }
    }
  ]
}